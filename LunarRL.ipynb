{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduccion al problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (1.26.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (4.13.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows:\n",
    "\n",
    "method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swig in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install swig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[box2d] in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (1.26.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (4.13.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (0.0.4)\n",
      "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
      "  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (2.6.1)\n",
      "Requirement already satisfied: swig==4.* in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (4.3.1)\n",
      "Building wheels for collected packages: box2d-py\n",
      "  Building wheel for box2d-py (setup.py): started\n",
      "  Building wheel for box2d-py (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for box2d-py\n",
      "Failed to build box2d-py\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [41 lines of output]\n",
      "      Using setuptools (version 80.2.0).\n",
      "      c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:289: UserWarning: Unknown distribution option: 'test_suite'\n",
      "        warnings.warn(msg)\n",
      "      c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: zlib/libpng License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self._finalize_license_expression()\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-312\\Box2D\n",
      "      copying library\\Box2D\\Box2D.py -> build\\lib.win-amd64-cpython-312\\Box2D\n",
      "      copying library\\Box2D\\__init__.py -> build\\lib.win-amd64-cpython-312\\Box2D\n",
      "      creating build\\lib.win-amd64-cpython-312\\Box2D\\b2\n",
      "      copying library\\Box2D\\b2\\__init__.py -> build\\lib.win-amd64-cpython-312\\Box2D\\b2\n",
      "      running build_ext\n",
      "      building 'Box2D._Box2D' extension\n",
      "      swigging Box2D\\Box2D.i to Box2D\\Box2D_wrap.cpp\n",
      "      swig.exe -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library\\Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D\\Box2D_wrap.cpp Box2D\\Box2D.i\n",
      "      Box2D\\Common\\b2Math.h(67) : Warning 302: Redefinition of identifier 'b2Vec2' by %extend ignored,\n",
      "      Box2D\\Box2D_math.i(47) : Warning 302: %extend definition of 'b2Vec2'.\n",
      "      Box2D\\Common\\b2Math.h(158) : Warning 302: Redefinition of identifier 'b2Vec3' by %extend ignored,\n",
      "      Box2D\\Box2D_math.i(168) : Warning 302: %extend definition of 'b2Vec3'.\n",
      "      Box2D\\Common\\b2Math.h(197) : Warning 302: Redefinition of identifier 'b2Mat22' by %extend ignored,\n",
      "      Box2D\\Box2D_math.i(301) : Warning 302: %extend definition of 'b2Mat22'.\n",
      "      Box2D\\Common\\b2Math.h(271) : Warning 302: Redefinition of identifier 'b2Mat33' by %extend ignored,\n",
      "      Box2D\\Box2D_math.i(372) : Warning 302: %extend definition of 'b2Mat33'.\n",
      "      Box2D\\Collision\\b2DynamicTree.h(44) : Warning 312: Nested union not currently supported (ignored).\n",
      "      Box2D\\Common\\b2Settings.h(144) : Warning 506: Can't wrap varargs with keyword arguments enabled\n",
      "      Box2D\\Common\\b2Math.h(91) : Warning 509: Overloaded method b2Vec2::operator ()(int32) effectively ignored,\n",
      "      Box2D\\Common\\b2Math.h(85) : Warning 509: as it is shadowed by b2Vec2::operator ()(int32) const.\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for box2d-py\n",
      "ERROR: Could not build wheels for box2d-py, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swig in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install swig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ufal.pybox2d in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.10.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install ufal.pybox2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linux:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gymnasium.farama.org/environments/box2d/lunar_lander/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lunar import LunarLanderEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow or Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (80.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.27.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (80.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (1.26.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gymnasium.spaces.box.Box'>\n",
      "<class 'gymnasium.spaces.discrete.Discrete'>\n"
     ]
    }
   ],
   "source": [
    "# Initialize the environment\n",
    "lunar = LunarLanderEnv()\n",
    "print(type(lunar.env.observation_space))\n",
    "print(type(lunar.env.action_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El espacio de acciones es un valor del 0 al 3 que indica que acciones tomará el modulo lunar para esa iteración.\n",
    "\n",
    "en concreto son las siguientes:\n",
    "\n",
    "|value| action                        |\n",
    "|-----|-------------------------------|\n",
    "| 0   | do nothing                    |\n",
    "| 1   | fire left orientation engine  |\n",
    "| 2   | fire main engine              |\n",
    "| 3   | fire right orientation engine |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lunar.env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El espacio de observaciones son un conjunto de valores flotantes y booleanos que indica el estado del modulo lunar.\n",
    "\n",
    "en concreto son las siguientes:\n",
    "\n",
    "|value| observation                               |\n",
    "|-----|-------------------------------------------|\n",
    "| 0   | coordenada X (float)                      |\n",
    "| 1   | coordenada Y (float)                      |\n",
    "| 2   | velocidad lineal X (float)                |\n",
    "| 3   | velocidad lineal Y (float)                |\n",
    "| 4   | Angulo en radianes desde -2π a +2π (float)|\n",
    "| 5   | Velocidad angula (float)                  |\n",
    "| 6   | Contacto de la pierna Izquierda (bool)    |\n",
    "| 7   | Contacto de la pierna Derecha (bool)      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
       "  -0.         -0.       ], [ 2.5        2.5       10.        10.         6.2831855 10.\n",
       "  1.         1.       ], (8,), float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se muestran los valores minimos y maximos del espacio de observaciones.\n",
    "lunar.env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observations: 8, actions: 4\n"
     ]
    }
   ],
   "source": [
    "observation_count = lunar.env.observation_space.shape[0] \n",
    "action_count = lunar.env.action_space.n\n",
    "\n",
    "print(f\"observations: {observation_count}, actions: {action_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
      "  -0.         -0.       ]\n",
      "[ 2.5        2.5       10.        10.         6.2831855 10.\n",
      "  1.         1.       ]\n"
     ]
    }
   ],
   "source": [
    "#valores minimos y maximos para las observaciones.\n",
    "print(lunar.env.observation_space.low) \n",
    "print(lunar.env.observation_space.high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample ofrece una combinacion aleatoria del conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(lunar.env.action_space.sample())  # Take a random action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2187959  -2.421489    1.9491879   1.8314897   0.13426743  3.480256\n",
      "  0.8669542   0.4764389 ]\n"
     ]
    }
   ],
   "source": [
    "print(lunar.env.observation_space.sample())  # Sample a random observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a random episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lunar_lander(steps_to_run_before_pause, agent, episodes=1):\n",
    "    \"\"\"\n",
    "    Test the Lunar Lander environment with a given agent.\n",
    "    \n",
    "    Parameters:\n",
    "    steps_to_run_before_pause (int): Number of steps to run before pausing for user input.\n",
    "    agent: The agent to be tested in the environment.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Initialize the environment\n",
    "    lunar = LunarLanderEnv(render_mode=\"human\")\n",
    "    \n",
    "    if(agent is not None):\n",
    "        # Set the agent's environment\n",
    "        agent.lunar = lunar\n",
    "        \n",
    "    for _ in range(episodes):\n",
    "        counter, score = 0, 0\n",
    "\n",
    "        while True:\n",
    "            if steps_to_run_before_pause != 0 and counter % steps_to_run_before_pause == 0:\n",
    "                input(\"Press Enter to continue...\")\n",
    "\n",
    "            if(agent is not None):\n",
    "                _, reward, done, action = agent.act()\n",
    "                \n",
    "            else:\n",
    "                # Sample a random action from the action space\n",
    "                action = lunar.env.action_space.sample()\n",
    "            \n",
    "                # Take a step in the environment\n",
    "                _, reward, done = lunar.take_action(action, verbose=True)\n",
    "                \n",
    "            score += reward\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "            if done:\n",
    "                print(f\"Episode finished, score: {score}\")\n",
    "                break\n",
    "        if(agent is not None):\n",
    "            # Reset the agent's environment for the next episode\n",
    "            agent.lunar.reset()\n",
    "        else:\n",
    "            # Reset the environment for the next episode\n",
    "            lunar.reset()\n",
    "        \n",
    "    # Close the environment\n",
    "    lunar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step taken: 0, New state: [ 0.00166883  1.3881148   0.08438908 -0.5195965  -0.00190616 -0.01892157\n",
      "  0.          0.        ], Reward: -1.4515650928726131, Done: False\n",
      "Step taken: 2, New state: [ 0.00240631  1.3768997   0.07518484 -0.49844936 -0.00332307 -0.02834108\n",
      "  0.          0.        ], Reward: 2.9114076202161927, Done: False\n",
      "Step taken: 3, New state: [ 0.00322847  1.3650912   0.08580646 -0.5248379  -0.00686809 -0.07090719\n",
      "  0.          0.        ], Reward: -1.9756296767186814, Done: False\n",
      "Step taken: 3, New state: [ 0.00414686  1.3526711   0.09786939 -0.5520375  -0.01282985 -0.1192463\n",
      "  0.          0.        ], Reward: -2.2684238412704176, Done: False\n",
      "Step taken: 3, New state: [ 0.00516119  1.3396467   0.10990463 -0.5789679  -0.02120073 -0.1674334\n",
      "  0.          0.        ], Reward: -2.431117548470978, Done: False\n",
      "Step taken: 1, New state: [ 0.00608511  1.3260224   0.09853856 -0.6056228  -0.02728627 -0.12172208\n",
      "  0.          0.        ], Reward: -1.7044954665225294, Done: False\n",
      "Step taken: 3, New state: [ 0.00709934  1.3117967   0.10988413 -0.63243514 -0.03564417 -0.16717337\n",
      "  0.          0.        ], Reward: -2.2760816931901773, Done: False\n",
      "Step taken: 2, New state: [ 0.00801506  1.2983251   0.10065247 -0.5989739  -0.04462206 -0.17957479\n",
      "  0.          0.        ], Reward: 3.602650760666262, Done: False\n",
      "Step taken: 1, New state: [ 0.0088541   1.284268    0.09100188 -0.6249894  -0.05164932 -0.14055833\n",
      "  0.          0.        ], Reward: -1.748393231124196, Done: False\n",
      "Step taken: 1, New state: [ 0.00962048  1.269628    0.08186956 -0.6508575  -0.05682873 -0.10359772\n",
      "  0.          0.        ], Reward: -1.5251867484750494, Done: False\n",
      "Step taken: 0, New state: [ 0.01038704  1.2543883   0.08188426 -0.67752844 -0.06200773 -0.10358936\n",
      "  0.          0.        ], Reward: -1.64181970378894, Done: False\n",
      "Step taken: 0, New state: [ 0.01115379  1.2385489   0.08189914 -0.70419925 -0.06718553 -0.10356544\n",
      "  0.          0.        ], Reward: -1.583264225355748, Done: False\n",
      "Step taken: 3, New state: [ 0.01198692  1.2221148   0.0902091  -0.73072904 -0.07401765 -0.13665488\n",
      "  0.          0.        ], Reward: -1.8037097195883962, Done: False\n",
      "Step taken: 0, New state: [ 0.01282034  1.2050813   0.09022875 -0.7574019  -0.08084801 -0.13661978\n",
      "  0.          0.        ], Reward: -1.6287478714804706, Done: False\n",
      "Step taken: 2, New state: [ 0.01386261  1.1884663   0.11039004 -0.73878354 -0.08695713 -0.12219354\n",
      "  0.          0.        ], Reward: 2.326529702859273, Done: False\n",
      "Step taken: 1, New state: [ 0.01483107  1.1712556   0.10111753 -0.76518023 -0.09120239 -0.08491236\n",
      "  0.          0.        ], Reward: -1.2194785694416044, Done: False\n",
      "Step taken: 0, New state: [ 0.01579962  1.153445    0.10112949 -0.7918465  -0.09544747 -0.08490951\n",
      "  0.          0.        ], Reward: -1.2894453796845653, Done: False\n",
      "Step taken: 2, New state: [ 0.01669779  1.1363319   0.09480699 -0.7609087  -0.10040575 -0.09917437\n",
      "  0.          0.        ], Reward: 4.0626235287443935, Done: False\n",
      "Step taken: 3, New state: [ 0.01766901  1.1186012   0.10398339 -0.7885067  -0.10722416 -0.13638052\n",
      "  0.          0.        ], Reward: -1.7945715620440683, Done: False\n",
      "Step taken: 1, New state: [ 0.01858034  1.1002914   0.09642489 -0.81415695 -0.11249027 -0.1053315\n",
      "  0.          0.        ], Reward: -1.1787272012889207, Done: False\n",
      "Step taken: 0, New state: [ 0.01949177  1.0813818   0.09643866 -0.84082884 -0.11775661 -0.10533632\n",
      "  0.          0.        ], Reward: -1.2869734652917941, Done: False\n",
      "Step taken: 3, New state: [ 0.02046909  1.0618523   0.10472278 -0.868541   -0.1247133  -0.13914631\n",
      "  0.          0.        ], Reward: -1.6239179597535258, Done: False\n",
      "Step taken: 1, New state: [ 0.02137938  1.0417243   0.09631159 -0.8950278  -0.12998399 -0.10542345\n",
      "  0.          0.        ], Reward: -1.0827950765779792, Done: False\n",
      "Step taken: 3, New state: [ 0.02238255  1.020988    0.10794421 -0.9222962  -0.13759178 -0.15216912\n",
      "  0.          0.        ], Reward: -1.55940657742937, Done: False\n",
      "Step taken: 1, New state: [ 0.0232974   0.99965     0.09689119 -0.94886035 -0.14298591 -0.10788272\n",
      "  0.          0.        ], Reward: -0.958525252555545, Done: False\n",
      "Step taken: 2, New state: [ 0.02444811  0.97913474  0.12003162 -0.9122709  -0.1479244  -0.0987697\n",
      "  0.          0.        ], Reward: 4.6203904709221435, Done: False\n",
      "Step taken: 2, New state: [ 0.02558298  0.9588857   0.11889584 -0.9005044  -0.15332963 -0.10810454\n",
      "  0.          0.        ], Reward: 2.36217830794011, Done: False\n",
      "Step taken: 3, New state: [ 0.02680864  0.93801916  0.13028847 -0.92821765 -0.16104998 -0.15440658\n",
      "  0.          0.        ], Reward: -1.61929426904092, Done: False\n",
      "Step taken: 3, New state: [ 0.02812014  0.91654146  0.14104226 -0.95566946 -0.17094338 -0.19786866\n",
      "  0.          0.        ], Reward: -1.7468254502609273, Done: False\n",
      "Step taken: 3, New state: [ 0.02949619  0.8944399   0.14915827 -0.98366106 -0.18252358 -0.23160431\n",
      "  0.          0.        ], Reward: -1.8718035385525968, Done: False\n",
      "Step taken: 1, New state: [ 0.03080721  0.87176585  0.14091697 -1.0089829  -0.19238809 -0.19729052\n",
      "  0.          0.        ], Reward: -1.141847685817395, Done: False\n",
      "Step taken: 3, New state: [ 0.03219748  0.84845823  0.1509138  -1.0374779  -0.2043498  -0.23923425\n",
      "  0.          0.        ], Reward: -1.864144456796878, Done: False\n",
      "Step taken: 3, New state: [ 0.03367586  0.8245179   0.16198441 -1.0660272  -0.2186266  -0.2855361\n",
      "  0.          0.        ], Reward: -2.0580450463622797, Done: False\n",
      "Step taken: 2, New state: [ 0.03520956  0.8012083   0.16803731 -1.0382289  -0.2334762  -0.2969918\n",
      "  0.          0.        ], Reward: 3.189851198278615, Done: False\n",
      "Step taken: 2, New state: [ 0.03690996  0.7778122   0.18426421 -1.0421516  -0.24794242 -0.28932446\n",
      "  0.          0.        ], Reward: -0.07488185993530577, Done: False\n",
      "Step taken: 1, New state: [ 0.03855467  0.7538492   0.17716266 -1.0672117  -0.26088026 -0.25875616\n",
      "  0.          0.        ], Reward: -1.2885517082125648, Done: False\n",
      "Step taken: 2, New state: [ 0.04039107  0.7297982   0.19583674 -1.0711552  -0.27336892 -0.24977288\n",
      "  0.          0.        ], Reward: 0.1337387253661973, Done: False\n",
      "Step taken: 0, New state: [ 0.04222775  0.7051492   0.19583157 -1.0978345  -0.28585744 -0.24977028\n",
      "  0.          0.        ], Reward: -1.4239661039529778, Done: False\n",
      "Step taken: 1, New state: [ 0.04399004  0.6799317   0.18642423 -1.1228123  -0.29635814 -0.21001418\n",
      "  0.          0.        ], Reward: -0.876090473300194, Done: False\n",
      "Step taken: 0, New state: [ 0.04575272  0.6541154   0.18642025 -1.1494877  -0.30685878 -0.21001263\n",
      "  0.          0.        ], Reward: -1.1183682439440474, Done: False\n",
      "Step taken: 0, New state: [ 0.04751568  0.62770057  0.18641613 -1.1761631  -0.31735933 -0.21001098\n",
      "  0.          0.        ], Reward: -1.0621822892880175, Done: False\n",
      "Step taken: 3, New state: [ 0.04934578  0.60066146  0.19480763 -1.2043682  -0.32963738 -0.24556093\n",
      "  0.          0.        ], Reward: -1.4943769927932908, Done: False\n",
      "Step taken: 0, New state: [ 0.05117626  0.57302433  0.1948016  -1.2310468  -0.34191528 -0.24555798\n",
      "  0.          0.        ], Reward: -1.124059422253083, Done: False\n",
      "Step taken: 0, New state: [ 0.05300732  0.5447891   0.19479536 -1.2577254  -0.35419306 -0.24555548\n",
      "  0.          0.        ], Reward: -1.0691071854242011, Done: False\n",
      "Step taken: 0, New state: [ 0.05483885  0.51595575  0.1947889  -1.2844037  -0.3664707  -0.24555293\n",
      "  0.          0.        ], Reward: -1.014718925114181, Done: False\n",
      "Step taken: 1, New state: [ 0.05660314  0.48657498  0.18613659 -1.3083328  -0.37675923 -0.20577085\n",
      "  0.          0.        ], Reward: -0.3999897390678189, Done: False\n",
      "Step taken: 2, New state: [ 0.05866241  0.457999    0.21589978 -1.2727104  -0.3873726  -0.21226756\n",
      "  0.          0.        ], Reward: 4.511666661891366, Done: False\n",
      "Step taken: 1, New state: [ 0.06066427  0.42884874  0.20869394 -1.2979033  -0.39643946 -0.18133709\n",
      "  0.          0.        ], Reward: -0.4426110991645078, Done: False\n",
      "Step taken: 0, New state: [ 0.06266661  0.39909947  0.20868997 -1.3245765  -0.40550625 -0.1813361\n",
      "  0.          0.        ], Reward: -0.6278963060522926, Done: False\n",
      "Step taken: 3, New state: [ 0.06474981  0.36869     0.21897578 -1.3546253  -0.41696998 -0.22927475\n",
      "  0.          0.        ], Reward: -1.3401320499456222, Done: False\n",
      "Step taken: 2, New state: [ 0.06686077  0.33833793  0.22233358 -1.3523488  -0.42913783 -0.24335691\n",
      "  0.          0.        ], Reward: 1.5990249186488483, Done: False\n",
      "Step taken: 1, New state: [ 0.06890583  0.30744103  0.21386139 -1.3760787  -0.43930048 -0.20325252\n",
      "  0.          0.        ], Reward: -0.2744472159448026, Done: False\n",
      "Step taken: 3, New state: [ 0.07101574  0.27591163  0.22191136 -1.4047792  -0.45124826 -0.23895565\n",
      "  0.          0.        ], Reward: -1.1684550733085632, Done: False\n",
      "Step taken: 0, New state: [ 0.07312612  0.24378385  0.22190364 -1.4314567  -0.46319592 -0.23895328\n",
      "  0.          0.        ], Reward: -0.7914061844145124, Done: False\n",
      "Step taken: 0, New state: [ 0.07523708  0.21105781  0.22189572 -1.4581339  -0.47514346 -0.23895094\n",
      "  0.          0.        ], Reward: -0.786624854651194, Done: False\n",
      "Step taken: 2, New state: [ 0.07768059  0.17859665  0.25494376 -1.4463983  -0.4869434  -0.23599939\n",
      "  0.          0.        ], Reward: 2.073450442163346, Done: False\n",
      "Step taken: 0, New state: [ 0.08012466  0.14553717  0.25493568 -1.4730753  -0.49874327 -0.23599716\n",
      "  0.          0.        ], Reward: -0.9454277397948374, Done: False\n",
      "Step taken: 2, New state: [ 0.08291979  0.1125234   0.28956315 -1.4709731  -0.51006883 -0.2265116\n",
      "  0.          0.        ], Reward: 0.7804309778154959, Done: False\n",
      "Step taken: 0, New state: [ 0.08571558  0.07891103  0.28955537 -1.4976491  -0.5213944  -0.22650972\n",
      "  0.          0.        ], Reward: -1.423893701578578, Done: False\n",
      "Step taken: 1, New state: [ 0.08845472  0.04473847  0.2823868  -1.522055   -0.5310495  -0.19310293\n",
      "  1.          0.        ], Reward: 8.478244866092242, Done: False\n",
      "Step taken: 3, New state: [ 0.09077644  0.01206315  0.22862399 -1.4509702  -0.53050417  0.00658953\n",
      "  1.          0.        ], Reward: 8.695341712170775, Done: False\n",
      "Step taken: 3, New state: [ 0.09372129 -0.01186136  0.09980983 -0.4220789  -0.42581546  4.4735656\n",
      "  1.          0.        ], Reward: -100, Done: True\n",
      "Episode finished, score: -113.73389358412192\n",
      "Environment closed.\n"
     ]
    }
   ],
   "source": [
    "test_lunar_lander(steps_to_run_before_pause=0, agent=None, episodes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cpu\n"
     ]
    }
   ],
   "source": [
    "from DQN import DQNAgent\n",
    "lunar = LunarLanderEnv(render_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNetwork:\n",
      " DQN(\n",
      "  (fc1): Linear(in_features=8, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n",
      "Ep    0 | Reward:  -174.11 | Eps: 0.994 | Loss: 0.1126\n",
      "0\n",
      "Ep    1 | Reward:  -163.19 | Eps: 0.988 | Loss: 0.3601\n",
      "0\n",
      "Ep    2 | Reward:  -257.11 | Eps: 0.982 | Loss: 85.2329\n",
      "0\n",
      "Ep    3 | Reward:  -103.20 | Eps: 0.976 | Loss: 4.0412\n",
      "0\n",
      "Ep    4 | Reward:  -143.25 | Eps: 0.970 | Loss: 2.4717\n",
      "0\n",
      "Ep    5 | Reward:  -105.36 | Eps: 0.965 | Loss: 4.0509\n",
      "0\n",
      "Ep    6 | Reward:  -176.92 | Eps: 0.959 | Loss: 58.3948\n",
      "0\n",
      "Ep    7 | Reward:  -136.25 | Eps: 0.953 | Loss: 15.5488\n",
      "0\n",
      "Ep    8 | Reward:  -229.95 | Eps: 0.947 | Loss: 6.3872\n",
      "0\n",
      "Ep    9 | Reward:  -310.83 | Eps: 0.942 | Loss: 40.5350\n",
      "0\n",
      "Ep   10 | Reward:  -141.93 | Eps: 0.936 | Loss: 56.8830\n",
      "0\n",
      "Ep   11 | Reward:  -131.27 | Eps: 0.930 | Loss: 12.5011\n",
      "0\n",
      "Ep   12 | Reward:  -198.06 | Eps: 0.925 | Loss: 195.6405\n",
      "0\n",
      "Ep   13 | Reward:  -128.07 | Eps: 0.919 | Loss: 123.8587\n",
      "0\n",
      "Ep   14 | Reward:  -323.64 | Eps: 0.914 | Loss: 1137.5146\n",
      "0\n",
      "Ep   15 | Reward:  -238.92 | Eps: 0.908 | Loss: 21.1870\n",
      "0\n",
      "Ep   16 | Reward:   -84.33 | Eps: 0.903 | Loss: 301.7011\n",
      "0\n",
      "Ep   17 | Reward:  -271.06 | Eps: 0.897 | Loss: 57.4139\n",
      "0\n",
      "Ep   18 | Reward:  -219.27 | Eps: 0.892 | Loss: 77.9596\n",
      "0\n",
      "Ep   19 | Reward:  -111.76 | Eps: 0.887 | Loss: 1944.1947\n",
      "0\n",
      "Ep   20 | Reward:  -211.61 | Eps: 0.881 | Loss: 23.5873\n",
      "0\n",
      "Ep   21 | Reward:  -132.22 | Eps: 0.876 | Loss: 711.7410\n",
      "0\n",
      "Ep   22 | Reward:  -160.97 | Eps: 0.871 | Loss: 67.2680\n",
      "0\n",
      "Ep   23 | Reward:  -352.78 | Eps: 0.866 | Loss: 57.3943\n",
      "0\n",
      "Ep   24 | Reward:   -88.91 | Eps: 0.860 | Loss: 431.8538\n",
      "0\n",
      "Ep   25 | Reward:  -152.00 | Eps: 0.855 | Loss: 203.8215\n",
      "0\n",
      "Ep   26 | Reward:   -79.60 | Eps: 0.850 | Loss: 650.0053\n",
      "0\n",
      "Ep   27 | Reward:  -176.76 | Eps: 0.845 | Loss: 59.3865\n",
      "0\n",
      "Ep   28 | Reward:  -222.88 | Eps: 0.840 | Loss: 383.9416\n",
      "0\n",
      "Ep   29 | Reward:  -103.27 | Eps: 0.835 | Loss: 1809.3533\n",
      "0\n",
      "Ep   30 | Reward:  -245.51 | Eps: 0.830 | Loss: 200.9848\n",
      "0\n",
      "Ep   31 | Reward:  -154.12 | Eps: 0.825 | Loss: 23.3762\n",
      "0\n",
      "Ep   32 | Reward:  -209.80 | Eps: 0.820 | Loss: 478.3862\n",
      "0\n",
      "Ep   33 | Reward:   -58.79 | Eps: 0.815 | Loss: 264.4153\n",
      "0\n",
      "Ep   34 | Reward:  -115.34 | Eps: 0.810 | Loss: 1134.8896\n",
      "0\n",
      "Ep   35 | Reward:  -142.97 | Eps: 0.805 | Loss: 166.5372\n",
      "0\n",
      "Ep   36 | Reward:  -337.99 | Eps: 0.800 | Loss: 73.8833\n",
      "0\n",
      "Ep   37 | Reward:  -186.44 | Eps: 0.796 | Loss: 365.3678\n",
      "0\n",
      "Ep   38 | Reward:   -76.05 | Eps: 0.791 | Loss: 269.6591\n",
      "0\n",
      "Ep   39 | Reward:  -143.90 | Eps: 0.786 | Loss: 226.6253\n",
      "0\n",
      "Ep   40 | Reward:  -331.83 | Eps: 0.781 | Loss: 638.2712\n",
      "0\n",
      "Ep   41 | Reward:  -160.95 | Eps: 0.777 | Loss: 1028.7485\n",
      "0\n",
      "Ep   42 | Reward:  -544.14 | Eps: 0.772 | Loss: 2079.8909\n",
      "0\n",
      "Ep   43 | Reward:  -193.68 | Eps: 0.767 | Loss: 195.4444\n",
      "0\n",
      "Ep   44 | Reward:  -114.46 | Eps: 0.763 | Loss: 4280.7363\n",
      "0\n",
      "Ep   45 | Reward:  -141.50 | Eps: 0.758 | Loss: 540.8362\n",
      "0\n",
      "Ep   46 | Reward:  -287.72 | Eps: 0.754 | Loss: 213.7278\n",
      "0\n",
      "Ep   47 | Reward:    -8.64 | Eps: 0.749 | Loss: 47.3931\n",
      "0\n",
      "Ep   48 | Reward:   -99.64 | Eps: 0.745 | Loss: 568.7872\n",
      "0\n",
      "Ep   49 | Reward:   -96.25 | Eps: 0.740 | Loss: 418.8761\n",
      "0\n",
      "Ep   50 | Reward:  -318.16 | Eps: 0.736 | Loss: 267.5950\n",
      "0\n",
      "Ep   51 | Reward:   -82.46 | Eps: 0.731 | Loss: 33.4913\n",
      "0\n",
      "Ep   52 | Reward:    -8.06 | Eps: 0.727 | Loss: 118.3712\n",
      "0\n",
      "Ep   53 | Reward:  -161.81 | Eps: 0.723 | Loss: 224.4653\n",
      "0\n",
      "Ep   54 | Reward:  -148.37 | Eps: 0.718 | Loss: 1093.6898\n",
      "0\n",
      "Ep   55 | Reward:   -68.92 | Eps: 0.714 | Loss: 245.9697\n",
      "0\n",
      "Ep   56 | Reward:  -443.50 | Eps: 0.710 | Loss: 55.7030\n",
      "0\n",
      "Ep   57 | Reward:   -86.83 | Eps: 0.705 | Loss: 436.7364\n",
      "0\n",
      "Ep   58 | Reward:  -103.51 | Eps: 0.701 | Loss: 87.1153\n",
      "0\n",
      "Ep   59 | Reward:   -84.49 | Eps: 0.697 | Loss: 159.8381\n",
      "0\n",
      "Ep   60 | Reward:  -115.22 | Eps: 0.693 | Loss: 402.6106\n",
      "0\n",
      "Ep   61 | Reward:  -110.99 | Eps: 0.689 | Loss: 169.2766\n",
      "0\n",
      "Ep   62 | Reward:  -115.35 | Eps: 0.684 | Loss: 854.0594\n",
      "0\n",
      "Ep   63 | Reward:  -177.22 | Eps: 0.680 | Loss: 70.3585\n",
      "0\n",
      "Ep   64 | Reward:  -102.18 | Eps: 0.676 | Loss: 110.4390\n",
      "0\n",
      "Ep   65 | Reward:  -220.12 | Eps: 0.672 | Loss: 889.8267\n",
      "0\n",
      "Ep   66 | Reward:   -83.52 | Eps: 0.668 | Loss: 609.6473\n",
      "0\n",
      "Ep   67 | Reward:  -372.65 | Eps: 0.664 | Loss: 241.9255\n",
      "0\n",
      "Ep   68 | Reward:   -89.10 | Eps: 0.660 | Loss: 147.5995\n",
      "0\n",
      "Ep   69 | Reward:  -106.34 | Eps: 0.656 | Loss: 119.4934\n",
      "0\n",
      "Ep   70 | Reward:  -207.38 | Eps: 0.652 | Loss: 1569.1311\n",
      "0\n",
      "Ep   71 | Reward:  -234.70 | Eps: 0.648 | Loss: 157.9982\n",
      "0\n",
      "Ep   72 | Reward:  -179.72 | Eps: 0.644 | Loss: 64.7024\n",
      "0\n",
      "Ep   73 | Reward:  -308.38 | Eps: 0.641 | Loss: 350.7964\n",
      "0\n",
      "Ep   74 | Reward:  -126.48 | Eps: 0.637 | Loss: 66.2619\n",
      "0\n",
      "Ep   75 | Reward:    10.84 | Eps: 0.633 | Loss: 373.3184\n",
      "0\n",
      "Ep   76 | Reward:  -314.41 | Eps: 0.629 | Loss: 73.0810\n",
      "0\n",
      "Ep   77 | Reward:  -199.08 | Eps: 0.625 | Loss: 95.2024\n",
      "0\n",
      "Ep   78 | Reward:  -163.79 | Eps: 0.622 | Loss: 138.8215\n",
      "0\n",
      "Ep   79 | Reward:  -474.66 | Eps: 0.618 | Loss: 48.1362\n",
      "0\n",
      "Ep   80 | Reward:  -399.10 | Eps: 0.614 | Loss: 57.9521\n",
      "0\n",
      "Ep   81 | Reward:   -50.08 | Eps: 0.610 | Loss: 93.5634\n",
      "0\n",
      "Ep   82 | Reward:  -235.85 | Eps: 0.607 | Loss: 199.0923\n",
      "0\n",
      "Ep   83 | Reward:   -60.79 | Eps: 0.603 | Loss: 65.1716\n",
      "0\n",
      "Ep   84 | Reward:   -40.08 | Eps: 0.600 | Loss: 106.3949\n",
      "0\n",
      "Ep   85 | Reward:  -215.04 | Eps: 0.596 | Loss: 92.5404\n",
      "0\n",
      "Ep   86 | Reward:  -201.74 | Eps: 0.592 | Loss: 74.6222\n",
      "0\n",
      "Ep   87 | Reward:  -532.91 | Eps: 0.589 | Loss: 78.0983\n",
      "0\n",
      "Ep   88 | Reward:  -465.16 | Eps: 0.585 | Loss: 148.4862\n",
      "0\n",
      "Ep   89 | Reward:  -157.49 | Eps: 0.582 | Loss: 270.5097\n",
      "0\n",
      "Ep   90 | Reward:  -234.63 | Eps: 0.578 | Loss: 19.0676\n",
      "0\n",
      "Ep   91 | Reward:  -135.63 | Eps: 0.575 | Loss: 86.0962\n",
      "0\n",
      "Ep   92 | Reward:   -93.45 | Eps: 0.571 | Loss: 98.4342\n",
      "0\n",
      "Ep   93 | Reward:  -283.66 | Eps: 0.568 | Loss: 47.6348\n",
      "0\n",
      "Ep   94 | Reward:    44.20 | Eps: 0.565 | Loss: 69.5852\n",
      "0\n",
      "Ep   95 | Reward:  -362.68 | Eps: 0.561 | Loss: 46.6963\n",
      "0\n",
      "Ep   96 | Reward:  -142.50 | Eps: 0.558 | Loss: 210.3566\n",
      "0\n",
      "Ep   97 | Reward:  -296.72 | Eps: 0.554 | Loss: 474.3115\n",
      "0\n",
      "Ep   98 | Reward:  -148.54 | Eps: 0.551 | Loss: 104.6371\n",
      "0\n",
      "Ep   99 | Reward:  -101.41 | Eps: 0.548 | Loss: 72.6544\n",
      "0\n",
      "Ep  100 | Reward:  -141.01 | Eps: 0.545 | Loss: 22.8814\n",
      "0\n",
      "Ep  101 | Reward:  -139.81 | Eps: 0.541 | Loss: 79.4182\n",
      "0\n",
      "Ep  102 | Reward:  -470.64 | Eps: 0.538 | Loss: 173.8538\n",
      "0\n",
      "Ep  103 | Reward:  -172.58 | Eps: 0.535 | Loss: 231.7103\n",
      "0\n",
      "Ep  104 | Reward:    33.95 | Eps: 0.532 | Loss: 184.1503\n",
      "0\n",
      "Ep  105 | Reward:  -121.81 | Eps: 0.528 | Loss: 114.8032\n",
      "0\n",
      "Ep  106 | Reward:  -327.65 | Eps: 0.525 | Loss: 216.6594\n",
      "0\n",
      "Ep  107 | Reward:  -195.54 | Eps: 0.522 | Loss: 96.6936\n",
      "0\n",
      "Ep  108 | Reward:  -299.44 | Eps: 0.519 | Loss: 66.9162\n",
      "0\n",
      "Ep  109 | Reward:   -18.35 | Eps: 0.516 | Loss: 267.6414\n",
      "0\n",
      "Ep  110 | Reward:   -10.12 | Eps: 0.513 | Loss: 69.8209\n",
      "0\n",
      "Ep  111 | Reward:  -184.95 | Eps: 0.510 | Loss: 87.0588\n",
      "0\n",
      "Ep  112 | Reward:  -257.33 | Eps: 0.507 | Loss: 52.7570\n",
      "0\n",
      "Ep  113 | Reward:  -195.10 | Eps: 0.504 | Loss: 205.5305\n",
      "0\n",
      "Ep  114 | Reward:  -160.01 | Eps: 0.501 | Loss: 165.3908\n",
      "0\n",
      "Ep  115 | Reward:  -328.46 | Eps: 0.498 | Loss: 51.0424\n",
      "0\n",
      "Ep  116 | Reward:  -154.61 | Eps: 0.495 | Loss: 55.4545\n",
      "0\n",
      "Ep  117 | Reward:   -73.12 | Eps: 0.492 | Loss: 33.6822\n",
      "0\n",
      "Ep  118 | Reward:  -220.67 | Eps: 0.489 | Loss: 68.0920\n",
      "0\n",
      "Ep  119 | Reward:  -205.07 | Eps: 0.486 | Loss: 216.0811\n",
      "0\n",
      "Ep  120 | Reward:  -289.11 | Eps: 0.483 | Loss: 86.0882\n",
      "0\n",
      "Ep  121 | Reward:  -532.23 | Eps: 0.480 | Loss: 316.8721\n",
      "0\n",
      "Ep  122 | Reward:  -215.94 | Eps: 0.477 | Loss: 292.8540\n",
      "0\n",
      "Ep  123 | Reward:   -57.26 | Eps: 0.474 | Loss: 129.5550\n",
      "0\n",
      "Ep  124 | Reward:  -153.93 | Eps: 0.471 | Loss: 127.3193\n",
      "0\n",
      "Ep  125 | Reward:  -116.85 | Eps: 0.468 | Loss: 47.0240\n",
      "0\n",
      "Ep  126 | Reward:  -335.88 | Eps: 0.466 | Loss: 32.7778\n",
      "0\n",
      "Ep  127 | Reward:   -94.34 | Eps: 0.463 | Loss: 46.7545\n",
      "0\n",
      "Ep  128 | Reward:  -467.98 | Eps: 0.460 | Loss: 78.7486\n",
      "0\n",
      "Ep  129 | Reward:  -511.44 | Eps: 0.457 | Loss: 96.8212\n",
      "0\n",
      "Ep  130 | Reward:  -275.82 | Eps: 0.455 | Loss: 85.8407\n",
      "0\n",
      "Ep  131 | Reward:  -216.85 | Eps: 0.452 | Loss: 147.9238\n",
      "0\n",
      "Ep  132 | Reward:  -301.14 | Eps: 0.449 | Loss: 293.5658\n",
      "0\n",
      "Ep  133 | Reward:  -159.26 | Eps: 0.446 | Loss: 148.1392\n",
      "0\n",
      "Ep  134 | Reward:  -333.31 | Eps: 0.444 | Loss: 85.2821\n",
      "0\n",
      "Ep  135 | Reward:  -142.14 | Eps: 0.441 | Loss: 39.8629\n",
      "0\n",
      "Ep  136 | Reward:  -262.88 | Eps: 0.438 | Loss: 85.4411\n",
      "0\n",
      "Ep  137 | Reward:  -174.07 | Eps: 0.436 | Loss: 63.6470\n",
      "0\n",
      "Ep  138 | Reward:  -367.24 | Eps: 0.433 | Loss: 33.2767\n",
      "0\n",
      "Ep  139 | Reward:  -316.15 | Eps: 0.431 | Loss: 351.6723\n",
      "0\n",
      "Ep  140 | Reward:   -93.31 | Eps: 0.428 | Loss: 88.1767\n",
      "0\n",
      "Ep  141 | Reward:  -410.90 | Eps: 0.425 | Loss: 251.6926\n",
      "0\n",
      "Ep  142 | Reward:  -259.81 | Eps: 0.423 | Loss: 169.1417\n",
      "0\n",
      "Ep  143 | Reward:   -65.60 | Eps: 0.420 | Loss: 43.7075\n",
      "0\n",
      "Ep  144 | Reward:  -168.01 | Eps: 0.418 | Loss: 46.7700\n",
      "0\n",
      "Ep  145 | Reward:  -265.90 | Eps: 0.415 | Loss: 90.7568\n",
      "0\n",
      "Ep  146 | Reward:  -179.19 | Eps: 0.413 | Loss: 58.5869\n",
      "0\n",
      "Ep  147 | Reward:   -40.57 | Eps: 0.410 | Loss: 128.8387\n",
      "0\n",
      "Ep  148 | Reward:   -14.71 | Eps: 0.408 | Loss: 116.4703\n",
      "0\n",
      "Ep  149 | Reward:  -100.20 | Eps: 0.405 | Loss: 93.7612\n",
      "0\n",
      "Ep  150 | Reward:  -379.89 | Eps: 0.403 | Loss: 68.6090\n",
      "0\n",
      "Ep  151 | Reward:   -11.56 | Eps: 0.401 | Loss: 239.3079\n",
      "0\n",
      "Ep  152 | Reward:  -272.28 | Eps: 0.398 | Loss: 79.0177\n",
      "0\n",
      "Ep  153 | Reward:    -9.48 | Eps: 0.396 | Loss: 221.2074\n",
      "0\n",
      "Ep  154 | Reward:   -17.63 | Eps: 0.393 | Loss: 230.4017\n",
      "0\n",
      "Ep  155 | Reward:  -266.11 | Eps: 0.391 | Loss: 132.2530\n",
      "0\n",
      "Ep  156 | Reward:  -175.70 | Eps: 0.389 | Loss: 61.5311\n",
      "0\n",
      "Ep  157 | Reward:  -155.52 | Eps: 0.386 | Loss: 98.8482\n",
      "0\n",
      "Ep  158 | Reward:  -131.15 | Eps: 0.384 | Loss: 91.9924\n",
      "0\n",
      "Ep  159 | Reward:   -27.31 | Eps: 0.382 | Loss: 48.8697\n",
      "0\n",
      "Ep  160 | Reward:  -166.22 | Eps: 0.379 | Loss: 64.8215\n",
      "0\n",
      "Ep  161 | Reward:  -310.27 | Eps: 0.377 | Loss: 66.8918\n",
      "0\n",
      "Ep  162 | Reward:  -106.83 | Eps: 0.375 | Loss: 68.0409\n",
      "0\n",
      "Ep  163 | Reward:  -154.98 | Eps: 0.373 | Loss: 173.7585\n",
      "0\n",
      "Ep  164 | Reward:  -326.37 | Eps: 0.370 | Loss: 123.2741\n",
      "0\n",
      "Ep  165 | Reward:   -42.88 | Eps: 0.368 | Loss: 26.0951\n",
      "0\n",
      "Ep  166 | Reward:  -390.34 | Eps: 0.366 | Loss: 113.5097\n",
      "0\n",
      "Ep  167 | Reward:  -108.58 | Eps: 0.364 | Loss: 38.8150\n",
      "0\n",
      "Ep  168 | Reward:  -147.88 | Eps: 0.362 | Loss: 253.2536\n",
      "0\n",
      "Ep  169 | Reward:  -194.53 | Eps: 0.359 | Loss: 87.6173\n",
      "0\n",
      "Ep  170 | Reward:  -288.40 | Eps: 0.357 | Loss: 20.3437\n",
      "0\n",
      "Ep  171 | Reward:  -393.15 | Eps: 0.355 | Loss: 125.3729\n",
      "0\n",
      "Ep  172 | Reward:  -197.13 | Eps: 0.353 | Loss: 322.7539\n",
      "0\n",
      "Ep  173 | Reward:   -87.29 | Eps: 0.351 | Loss: 51.1679\n",
      "0\n",
      "Ep  174 | Reward:  -277.62 | Eps: 0.349 | Loss: 87.7136\n",
      "0\n",
      "Ep  175 | Reward:  -181.88 | Eps: 0.347 | Loss: 42.0447\n",
      "0\n",
      "Ep  176 | Reward:  -250.11 | Eps: 0.345 | Loss: 80.6655\n",
      "0\n",
      "Ep  177 | Reward:  -308.37 | Eps: 0.343 | Loss: 80.0053\n",
      "0\n",
      "Ep  178 | Reward:  -308.30 | Eps: 0.341 | Loss: 85.4904\n",
      "0\n",
      "Ep  179 | Reward:  -285.37 | Eps: 0.338 | Loss: 34.6445\n",
      "0\n",
      "Ep  180 | Reward:  -226.86 | Eps: 0.336 | Loss: 528.7286\n",
      "0\n",
      "Ep  181 | Reward:  -115.66 | Eps: 0.334 | Loss: 90.6408\n",
      "0\n",
      "Ep  182 | Reward:  -440.32 | Eps: 0.332 | Loss: 60.9712\n",
      "0\n",
      "Ep  183 | Reward:  -470.20 | Eps: 0.330 | Loss: 147.8250\n",
      "0\n",
      "Ep  184 | Reward:  -181.53 | Eps: 0.328 | Loss: 83.9510\n",
      "0\n",
      "Ep  185 | Reward:  -523.38 | Eps: 0.326 | Loss: 32.9910\n",
      "0\n",
      "Ep  186 | Reward:  -176.57 | Eps: 0.325 | Loss: 36.3535\n",
      "0\n",
      "Ep  187 | Reward:  -139.67 | Eps: 0.323 | Loss: 31.1926\n",
      "0\n",
      "Ep  188 | Reward:  -204.15 | Eps: 0.321 | Loss: 79.0788\n",
      "0\n",
      "Ep  189 | Reward:  -377.92 | Eps: 0.319 | Loss: 101.7223\n",
      "0\n",
      "Ep  190 | Reward:  -231.03 | Eps: 0.317 | Loss: 59.5842\n",
      "0\n",
      "Ep  191 | Reward:  -304.45 | Eps: 0.315 | Loss: 53.2269\n",
      "0\n",
      "Ep  192 | Reward:  -349.32 | Eps: 0.313 | Loss: 18.2177\n",
      "0\n",
      "Ep  193 | Reward:  -228.65 | Eps: 0.311 | Loss: 52.2226\n",
      "0\n",
      "Ep  194 | Reward:  -402.90 | Eps: 0.309 | Loss: 71.7947\n",
      "0\n",
      "Ep  195 | Reward:  -400.75 | Eps: 0.307 | Loss: 115.7008\n",
      "0\n",
      "Ep  196 | Reward:  -281.51 | Eps: 0.306 | Loss: 85.3884\n",
      "0\n",
      "Ep  197 | Reward:  -226.85 | Eps: 0.304 | Loss: 164.0151\n",
      "0\n",
      "Ep  198 | Reward:  -200.48 | Eps: 0.302 | Loss: 175.4522\n",
      "0\n",
      "Ep  199 | Reward:  -284.30 | Eps: 0.300 | Loss: 74.4003\n",
      "0\n",
      "Ep  200 | Reward:  -453.53 | Eps: 0.298 | Loss: 127.6039\n",
      "0\n",
      "Ep  201 | Reward:  -267.19 | Eps: 0.297 | Loss: 76.0154\n",
      "0\n",
      "Ep  202 | Reward:  -553.06 | Eps: 0.295 | Loss: 58.2869\n",
      "0\n",
      "Ep  203 | Reward:  -205.22 | Eps: 0.293 | Loss: 54.3624\n",
      "0\n",
      "Ep  204 | Reward:  -178.18 | Eps: 0.291 | Loss: 52.4737\n",
      "0\n",
      "Ep  205 | Reward:     3.87 | Eps: 0.289 | Loss: 45.9363\n",
      "0\n",
      "Ep  206 | Reward:  -191.23 | Eps: 0.288 | Loss: 274.2668\n",
      "0\n",
      "Ep  207 | Reward:  -411.76 | Eps: 0.286 | Loss: 90.4134\n",
      "0\n",
      "Ep  208 | Reward:  -256.55 | Eps: 0.284 | Loss: 111.5696\n",
      "0\n",
      "Ep  209 | Reward:  -367.64 | Eps: 0.283 | Loss: 86.8219\n",
      "0\n",
      "Ep  210 | Reward:  -382.35 | Eps: 0.281 | Loss: 93.2724\n",
      "0\n",
      "Ep  211 | Reward:  -265.71 | Eps: 0.279 | Loss: 67.3495\n",
      "0\n",
      "Ep  212 | Reward:  -428.30 | Eps: 0.278 | Loss: 70.8291\n",
      "0\n",
      "Ep  213 | Reward:  -139.87 | Eps: 0.276 | Loss: 110.8818\n",
      "0\n",
      "Ep  214 | Reward:  -344.64 | Eps: 0.274 | Loss: 127.2294\n",
      "0\n",
      "Ep  215 | Reward:  -138.58 | Eps: 0.273 | Loss: 108.0370\n",
      "0\n",
      "Ep  216 | Reward:  -355.63 | Eps: 0.271 | Loss: 51.8693\n",
      "0\n",
      "Ep  217 | Reward:  -282.26 | Eps: 0.269 | Loss: 112.2306\n",
      "0\n",
      "Ep  218 | Reward:  -308.09 | Eps: 0.268 | Loss: 122.7257\n",
      "0\n",
      "Ep  219 | Reward:  -261.03 | Eps: 0.266 | Loss: 62.5501\n",
      "0\n",
      "Ep  220 | Reward:  -251.67 | Eps: 0.264 | Loss: 119.5595\n",
      "0\n",
      "Ep  221 | Reward:  -246.72 | Eps: 0.263 | Loss: 133.6742\n",
      "0\n",
      "Ep  222 | Reward:  -217.18 | Eps: 0.261 | Loss: 57.3134\n",
      "0\n",
      "Ep  223 | Reward:   -86.48 | Eps: 0.260 | Loss: 113.1060\n",
      "0\n",
      "Ep  224 | Reward:  -150.24 | Eps: 0.258 | Loss: 384.7207\n",
      "0\n",
      "Ep  225 | Reward:  -224.59 | Eps: 0.257 | Loss: 86.8500\n",
      "0\n",
      "Ep  226 | Reward:   -71.21 | Eps: 0.255 | Loss: 147.2602\n",
      "0\n",
      "Ep  227 | Reward:  -311.32 | Eps: 0.254 | Loss: 76.1511\n",
      "0\n",
      "Ep  228 | Reward:  -264.19 | Eps: 0.252 | Loss: 148.9319\n",
      "0\n",
      "Ep  229 | Reward:  -374.28 | Eps: 0.251 | Loss: 162.7674\n",
      "0\n",
      "Ep  230 | Reward:  -309.10 | Eps: 0.249 | Loss: 84.4633\n",
      "0\n",
      "Ep  231 | Reward:  -231.59 | Eps: 0.248 | Loss: 185.2280\n",
      "0\n",
      "Ep  232 | Reward:  -257.66 | Eps: 0.246 | Loss: 116.6714\n",
      "0\n",
      "Ep  233 | Reward:  -331.52 | Eps: 0.245 | Loss: 153.9944\n",
      "0\n",
      "Ep  234 | Reward:  -212.33 | Eps: 0.243 | Loss: 146.8313\n",
      "0\n",
      "Ep  235 | Reward:  -455.05 | Eps: 0.242 | Loss: 87.7430\n",
      "0\n",
      "Ep  236 | Reward:    -5.78 | Eps: 0.240 | Loss: 68.3603\n",
      "0\n",
      "Ep  237 | Reward:  -199.57 | Eps: 0.239 | Loss: 182.1606\n",
      "0\n",
      "Ep  238 | Reward:  -212.69 | Eps: 0.237 | Loss: 241.3582\n",
      "0\n",
      "Ep  239 | Reward:    24.67 | Eps: 0.236 | Loss: 93.0030\n",
      "0\n",
      "Ep  240 | Reward:  -232.41 | Eps: 0.234 | Loss: 120.8242\n",
      "0\n",
      "Ep  241 | Reward:  -222.58 | Eps: 0.233 | Loss: 63.9429\n",
      "0\n",
      "Ep  242 | Reward:  -256.64 | Eps: 0.232 | Loss: 81.3098\n",
      "0\n",
      "Ep  243 | Reward:  -460.72 | Eps: 0.230 | Loss: 87.6293\n",
      "0\n",
      "Ep  244 | Reward:  -205.44 | Eps: 0.229 | Loss: 150.2973\n",
      "0\n",
      "Ep  245 | Reward:  -260.44 | Eps: 0.228 | Loss: 161.8191\n",
      "0\n",
      "Ep  246 | Reward:  -180.63 | Eps: 0.226 | Loss: 97.8434\n",
      "0\n",
      "Ep  247 | Reward:  -390.15 | Eps: 0.225 | Loss: 166.3833\n",
      "0\n",
      "Ep  248 | Reward:  -379.02 | Eps: 0.223 | Loss: 131.8271\n",
      "0\n",
      "Ep  249 | Reward:  -290.97 | Eps: 0.222 | Loss: 82.4722\n",
      "0\n",
      "Ep  250 | Reward:  -304.41 | Eps: 0.221 | Loss: 159.5692\n",
      "0\n",
      "Ep  251 | Reward:  -420.88 | Eps: 0.219 | Loss: 128.4222\n",
      "0\n",
      "Ep  252 | Reward:  -290.17 | Eps: 0.218 | Loss: 199.7274\n",
      "0\n",
      "Ep  253 | Reward:  -173.18 | Eps: 0.217 | Loss: 70.7614\n",
      "0\n",
      "Ep  254 | Reward:  -394.03 | Eps: 0.216 | Loss: 112.8811\n",
      "0\n",
      "Ep  255 | Reward:  -303.64 | Eps: 0.214 | Loss: 125.7894\n",
      "0\n",
      "Ep  256 | Reward:  -204.06 | Eps: 0.213 | Loss: 193.0979\n",
      "0\n",
      "Ep  257 | Reward:  -197.32 | Eps: 0.212 | Loss: 180.8065\n",
      "0\n",
      "Ep  258 | Reward:  -391.46 | Eps: 0.210 | Loss: 141.3306\n",
      "0\n",
      "Ep  259 | Reward:  -274.66 | Eps: 0.209 | Loss: 91.4480\n",
      "0\n",
      "Ep  260 | Reward:  -172.02 | Eps: 0.208 | Loss: 78.9280\n",
      "0\n",
      "Ep  261 | Reward:   -39.14 | Eps: 0.207 | Loss: 133.3179\n",
      "0\n",
      "Ep  262 | Reward:  -309.24 | Eps: 0.205 | Loss: 234.3221\n",
      "0\n",
      "Ep  263 | Reward:  -415.08 | Eps: 0.204 | Loss: 77.6503\n",
      "0\n",
      "Ep  264 | Reward:  -468.30 | Eps: 0.203 | Loss: 116.0427\n",
      "0\n",
      "Ep  265 | Reward:  -344.09 | Eps: 0.202 | Loss: 97.0681\n",
      "0\n",
      "Ep  266 | Reward:  -194.61 | Eps: 0.201 | Loss: 206.0683\n",
      "0\n",
      "Ep  267 | Reward:  -180.64 | Eps: 0.199 | Loss: 158.6519\n",
      "0\n",
      "Ep  268 | Reward:  -406.61 | Eps: 0.198 | Loss: 64.5749\n",
      "0\n",
      "Ep  269 | Reward:  -243.83 | Eps: 0.197 | Loss: 66.3818\n",
      "0\n",
      "Ep  270 | Reward:  -135.94 | Eps: 0.196 | Loss: 118.5469\n",
      "0\n",
      "Ep  271 | Reward:  -225.08 | Eps: 0.195 | Loss: 156.2904\n",
      "0\n",
      "Ep  272 | Reward:  -316.10 | Eps: 0.193 | Loss: 181.0748\n",
      "0\n",
      "Ep  273 | Reward:  -265.25 | Eps: 0.192 | Loss: 207.6948\n",
      "0\n",
      "Ep  274 | Reward:  -427.32 | Eps: 0.191 | Loss: 121.0709\n",
      "0\n",
      "Ep  275 | Reward:  -248.01 | Eps: 0.190 | Loss: 262.0349\n",
      "0\n",
      "Ep  276 | Reward:  -231.07 | Eps: 0.189 | Loss: 102.3306\n",
      "0\n",
      "Ep  277 | Reward:  -289.59 | Eps: 0.188 | Loss: 133.8878\n",
      "0\n",
      "Ep  278 | Reward:  -262.96 | Eps: 0.187 | Loss: 127.4100\n",
      "0\n",
      "Ep  279 | Reward:  -461.41 | Eps: 0.185 | Loss: 260.0351\n",
      "0\n",
      "Ep  280 | Reward:  -377.06 | Eps: 0.184 | Loss: 205.5832\n",
      "0\n",
      "Ep  281 | Reward:  -334.13 | Eps: 0.183 | Loss: 117.4740\n",
      "0\n",
      "Ep  282 | Reward:  -388.37 | Eps: 0.182 | Loss: 76.6126\n",
      "0\n",
      "Ep  283 | Reward:   -91.92 | Eps: 0.181 | Loss: 123.7808\n",
      "0\n",
      "Ep  284 | Reward:  -307.65 | Eps: 0.180 | Loss: 334.2031\n",
      "0\n",
      "Ep  285 | Reward:  -237.69 | Eps: 0.179 | Loss: 187.5913\n",
      "0\n",
      "Ep  286 | Reward:   -66.41 | Eps: 0.178 | Loss: 279.7471\n",
      "0\n",
      "Ep  287 | Reward:  -281.65 | Eps: 0.177 | Loss: 117.3067\n",
      "0\n",
      "Ep  288 | Reward:  -442.53 | Eps: 0.176 | Loss: 81.8180\n",
      "0\n",
      "Ep  289 | Reward:  -201.22 | Eps: 0.175 | Loss: 137.3728\n",
      "0\n",
      "Ep  290 | Reward:  -362.49 | Eps: 0.174 | Loss: 143.4405\n",
      "0\n",
      "Ep  291 | Reward:  -409.01 | Eps: 0.173 | Loss: 181.0188\n",
      "0\n",
      "Ep  292 | Reward:  -335.21 | Eps: 0.171 | Loss: 107.7772\n",
      "0\n",
      "Ep  293 | Reward:  -160.44 | Eps: 0.170 | Loss: 165.3992\n",
      "0\n",
      "Ep  294 | Reward:  -166.60 | Eps: 0.169 | Loss: 103.2564\n",
      "0\n",
      "Ep  295 | Reward:  -314.42 | Eps: 0.168 | Loss: 92.1806\n",
      "0\n",
      "Ep  296 | Reward:  -408.33 | Eps: 0.167 | Loss: 87.9094\n",
      "0\n",
      "Ep  297 | Reward:  -413.72 | Eps: 0.166 | Loss: 158.2029\n",
      "0\n",
      "Ep  298 | Reward:  -330.31 | Eps: 0.165 | Loss: 133.3708\n",
      "0\n",
      "Ep  299 | Reward:  -169.74 | Eps: 0.164 | Loss: 146.9412\n",
      "0\n",
      "Ep  300 | Reward:  -129.15 | Eps: 0.163 | Loss: 155.0477\n",
      "0\n",
      "Ep  301 | Reward:  -438.46 | Eps: 0.162 | Loss: 157.6818\n",
      "0\n",
      "Ep  302 | Reward:  -358.13 | Eps: 0.161 | Loss: 101.6391\n",
      "0\n",
      "Ep  303 | Reward:  -472.96 | Eps: 0.160 | Loss: 63.8026\n",
      "0\n",
      "Ep  304 | Reward:  -233.50 | Eps: 0.160 | Loss: 109.0464\n",
      "0\n",
      "Ep  305 | Reward:  -393.28 | Eps: 0.159 | Loss: 89.7293\n",
      "0\n",
      "Ep  306 | Reward:  -211.43 | Eps: 0.158 | Loss: 124.1282\n",
      "0\n",
      "Ep  307 | Reward:  -157.14 | Eps: 0.157 | Loss: 116.4028\n",
      "0\n",
      "Ep  308 | Reward:  -273.25 | Eps: 0.156 | Loss: 118.5240\n",
      "0\n",
      "Ep  309 | Reward:  -266.79 | Eps: 0.155 | Loss: 117.5080\n",
      "0\n",
      "Ep  310 | Reward:  -373.60 | Eps: 0.154 | Loss: 77.1759\n",
      "0\n",
      "Ep  311 | Reward:  -150.09 | Eps: 0.153 | Loss: 225.1414\n",
      "0\n",
      "Ep  312 | Reward:  -176.69 | Eps: 0.152 | Loss: 153.6689\n",
      "0\n",
      "Ep  313 | Reward:  -339.02 | Eps: 0.151 | Loss: 198.7506\n",
      "0\n",
      "Ep  314 | Reward:  -420.92 | Eps: 0.150 | Loss: 249.3608\n",
      "0\n",
      "Ep  315 | Reward:   -38.81 | Eps: 0.149 | Loss: 150.1622\n",
      "0\n",
      "Ep  316 | Reward:   -84.20 | Eps: 0.148 | Loss: 132.2843\n",
      "0\n",
      "Ep  317 | Reward:  -391.28 | Eps: 0.148 | Loss: 92.6163\n",
      "0\n",
      "Ep  318 | Reward:   -89.33 | Eps: 0.147 | Loss: 210.7889\n",
      "0\n",
      "Ep  319 | Reward:  -204.20 | Eps: 0.146 | Loss: 248.7241\n",
      "0\n",
      "Ep  320 | Reward:  -428.03 | Eps: 0.145 | Loss: 125.8349\n",
      "0\n",
      "Ep  321 | Reward:  -242.33 | Eps: 0.144 | Loss: 203.0066\n",
      "0\n",
      "Ep  322 | Reward:  -205.62 | Eps: 0.143 | Loss: 146.7320\n",
      "0\n",
      "Ep  323 | Reward:   -99.22 | Eps: 0.142 | Loss: 413.1520\n",
      "0\n",
      "Ep  324 | Reward:  -384.74 | Eps: 0.141 | Loss: 171.2583\n",
      "0\n",
      "Ep  325 | Reward:  -375.55 | Eps: 0.141 | Loss: 74.7203\n",
      "0\n",
      "Ep  326 | Reward:  -332.07 | Eps: 0.140 | Loss: 123.3803\n",
      "0\n",
      "Ep  327 | Reward:  -291.63 | Eps: 0.139 | Loss: 93.2871\n",
      "0\n",
      "Ep  328 | Reward:    58.66 | Eps: 0.138 | Loss: 84.2498\n",
      "0\n",
      "Ep  329 | Reward:  -186.39 | Eps: 0.137 | Loss: 104.5408\n",
      "0\n",
      "Ep  330 | Reward:  -146.26 | Eps: 0.136 | Loss: 82.9954\n",
      "0\n",
      "Ep  331 | Reward:  -269.05 | Eps: 0.136 | Loss: 215.7192\n",
      "0\n",
      "Ep  332 | Reward:  -128.81 | Eps: 0.135 | Loss: 122.2339\n",
      "0\n",
      "Ep  333 | Reward:   -93.29 | Eps: 0.134 | Loss: 200.0548\n",
      "0\n",
      "Ep  334 | Reward:  -284.90 | Eps: 0.133 | Loss: 112.3674\n",
      "0\n",
      "Ep  335 | Reward:  -208.89 | Eps: 0.132 | Loss: 105.8103\n",
      "0\n",
      "Ep  336 | Reward:  -370.67 | Eps: 0.132 | Loss: 60.8787\n",
      "0\n",
      "Ep  337 | Reward:  -144.65 | Eps: 0.131 | Loss: 129.9413\n",
      "0\n",
      "Ep  338 | Reward:  -410.33 | Eps: 0.130 | Loss: 119.7657\n",
      "0\n",
      "Ep  339 | Reward:  -300.93 | Eps: 0.129 | Loss: 157.5460\n",
      "0\n",
      "Ep  340 | Reward:  -226.30 | Eps: 0.128 | Loss: 113.5484\n",
      "0\n",
      "Ep  341 | Reward:  -210.60 | Eps: 0.128 | Loss: 79.3923\n",
      "0\n",
      "Ep  342 | Reward:  -129.89 | Eps: 0.127 | Loss: 119.8133\n",
      "0\n",
      "Ep  343 | Reward:  -398.49 | Eps: 0.126 | Loss: 202.0149\n",
      "0\n",
      "Ep  344 | Reward:  -148.37 | Eps: 0.125 | Loss: 127.2397\n",
      "0\n",
      "Ep  345 | Reward:  -281.52 | Eps: 0.125 | Loss: 49.6041\n",
      "0\n",
      "Ep  346 | Reward:  -425.31 | Eps: 0.124 | Loss: 114.4130\n",
      "0\n",
      "Ep  347 | Reward:  -184.93 | Eps: 0.123 | Loss: 105.3631\n",
      "0\n",
      "Ep  348 | Reward:   -84.41 | Eps: 0.122 | Loss: 54.1973\n",
      "0\n",
      "Ep  349 | Reward:  -272.64 | Eps: 0.122 | Loss: 95.8018\n",
      "0\n",
      "Ep  350 | Reward:  -167.71 | Eps: 0.121 | Loss: 65.3719\n",
      "0\n",
      "Ep  351 | Reward:  -223.07 | Eps: 0.120 | Loss: 160.1824\n",
      "0\n",
      "Ep  352 | Reward:  -348.00 | Eps: 0.120 | Loss: 89.3180\n",
      "0\n",
      "Ep  353 | Reward:  -122.00 | Eps: 0.119 | Loss: 144.8184\n",
      "0\n",
      "Ep  354 | Reward:  -242.94 | Eps: 0.118 | Loss: 96.7609\n",
      "0\n",
      "Ep  355 | Reward:  -336.92 | Eps: 0.117 | Loss: 46.8189\n",
      "0\n",
      "Ep  356 | Reward:  -380.04 | Eps: 0.117 | Loss: 116.7870\n",
      "0\n",
      "Ep  357 | Reward:  -347.20 | Eps: 0.116 | Loss: 124.8653\n",
      "0\n",
      "Ep  358 | Reward:  -297.72 | Eps: 0.115 | Loss: 664.8696\n",
      "0\n",
      "Ep  359 | Reward:  -428.89 | Eps: 0.115 | Loss: 71.8300\n",
      "0\n",
      "Ep  360 | Reward:  -361.18 | Eps: 0.114 | Loss: 139.6322\n",
      "0\n",
      "Ep  361 | Reward:  -292.22 | Eps: 0.113 | Loss: 1295.8840\n",
      "0\n",
      "Ep  362 | Reward:  -298.66 | Eps: 0.113 | Loss: 158.5152\n",
      "0\n",
      "Ep  363 | Reward:  -288.48 | Eps: 0.112 | Loss: 57.8622\n",
      "0\n",
      "Ep  364 | Reward:  -267.78 | Eps: 0.111 | Loss: 53.7773\n",
      "0\n",
      "Ep  365 | Reward:  -256.56 | Eps: 0.111 | Loss: 120.6806\n",
      "0\n",
      "Ep  366 | Reward:  -376.25 | Eps: 0.110 | Loss: 77.0285\n",
      "0\n",
      "Ep  367 | Reward:  -248.17 | Eps: 0.109 | Loss: 191.9990\n",
      "0\n",
      "Ep  368 | Reward:  -276.01 | Eps: 0.109 | Loss: 662.0942\n",
      "0\n",
      "Ep  369 | Reward:  -201.35 | Eps: 0.108 | Loss: 77.3129\n",
      "0\n",
      "Ep  370 | Reward:  -345.03 | Eps: 0.107 | Loss: 91.8069\n",
      "0\n",
      "Ep  371 | Reward:  -417.14 | Eps: 0.107 | Loss: 157.0428\n",
      "0\n",
      "Ep  372 | Reward:  -420.03 | Eps: 0.106 | Loss: 62.4786\n",
      "0\n",
      "Ep  373 | Reward:  -415.26 | Eps: 0.105 | Loss: 102.3761\n",
      "0\n",
      "Ep  374 | Reward:  -421.01 | Eps: 0.105 | Loss: 125.9537\n",
      "0\n",
      "Ep  375 | Reward:   -63.72 | Eps: 0.104 | Loss: 148.2578\n",
      "0\n",
      "Ep  376 | Reward:  -371.00 | Eps: 0.103 | Loss: 92.2110\n",
      "0\n",
      "Ep  377 | Reward:  -390.12 | Eps: 0.103 | Loss: 496.4281\n",
      "0\n",
      "Ep  378 | Reward:  -396.42 | Eps: 0.102 | Loss: 217.9692\n",
      "0\n",
      "Ep  379 | Reward:  -329.59 | Eps: 0.102 | Loss: 668.2115\n",
      "0\n",
      "Ep  380 | Reward:  -372.62 | Eps: 0.101 | Loss: 225.2510\n",
      "0\n",
      "Ep  381 | Reward:  -372.82 | Eps: 0.100 | Loss: 125.9946\n",
      "0\n",
      "Ep  382 | Reward:  -435.77 | Eps: 0.100 | Loss: 109.3143\n",
      "0\n",
      "Ep  383 | Reward:  -107.80 | Eps: 0.099 | Loss: 79.6292\n",
      "0\n",
      "Ep  384 | Reward:  -496.48 | Eps: 0.099 | Loss: 88.9180\n",
      "0\n",
      "Ep  385 | Reward:  -439.63 | Eps: 0.098 | Loss: 277.3570\n",
      "0\n",
      "Ep  386 | Reward:  -145.85 | Eps: 0.097 | Loss: 665.6890\n",
      "0\n",
      "Ep  387 | Reward:  -416.38 | Eps: 0.097 | Loss: 167.3718\n",
      "0\n",
      "Ep  388 | Reward:  -369.02 | Eps: 0.096 | Loss: 167.6990\n",
      "0\n",
      "Ep  389 | Reward:  -254.71 | Eps: 0.096 | Loss: 108.3127\n",
      "0\n",
      "Ep  390 | Reward:  -430.68 | Eps: 0.095 | Loss: 76.5523\n",
      "0\n",
      "Ep  391 | Reward:  -428.41 | Eps: 0.095 | Loss: 159.5949\n",
      "0\n",
      "Ep  392 | Reward:  -424.04 | Eps: 0.094 | Loss: 557.4330\n",
      "0\n",
      "Ep  393 | Reward:   -54.27 | Eps: 0.093 | Loss: 49.5479\n",
      "0\n",
      "Ep  394 | Reward:  -380.53 | Eps: 0.093 | Loss: 158.4224\n",
      "0\n",
      "Ep  395 | Reward:   -68.86 | Eps: 0.092 | Loss: 125.6390\n",
      "0\n",
      "Ep  396 | Reward:  -321.61 | Eps: 0.092 | Loss: 92.5647\n",
      "0\n",
      "Ep  397 | Reward:  -120.08 | Eps: 0.091 | Loss: 136.4253\n",
      "0\n",
      "Ep  398 | Reward:  -399.92 | Eps: 0.091 | Loss: 53.3486\n",
      "0\n",
      "Ep  399 | Reward:  -265.62 | Eps: 0.090 | Loss: 245.3830\n",
      "0\n",
      "Ep  400 | Reward:  -373.45 | Eps: 0.090 | Loss: 59.8247\n",
      "0\n",
      "Ep  401 | Reward:  -373.46 | Eps: 0.089 | Loss: 135.2856\n",
      "0\n",
      "Ep  402 | Reward:  -252.09 | Eps: 0.088 | Loss: 104.0104\n",
      "0\n",
      "Ep  403 | Reward:  -308.76 | Eps: 0.088 | Loss: 86.1858\n",
      "0\n",
      "Ep  404 | Reward:  -243.38 | Eps: 0.087 | Loss: 179.9532\n",
      "0\n",
      "Ep  405 | Reward:  -160.96 | Eps: 0.087 | Loss: 111.7602\n",
      "0\n",
      "Ep  406 | Reward:  -205.43 | Eps: 0.086 | Loss: 80.7785\n",
      "0\n",
      "Ep  407 | Reward:  -330.12 | Eps: 0.086 | Loss: 75.2303\n",
      "0\n",
      "Ep  408 | Reward:  -403.05 | Eps: 0.085 | Loss: 63.0259\n",
      "0\n",
      "Ep  409 | Reward:  -331.69 | Eps: 0.085 | Loss: 72.3008\n",
      "0\n",
      "Ep  410 | Reward:  -380.95 | Eps: 0.084 | Loss: 100.1225\n",
      "0\n",
      "Ep  411 | Reward:  -374.58 | Eps: 0.084 | Loss: 51.8049\n",
      "0\n",
      "Ep  412 | Reward:  -344.75 | Eps: 0.083 | Loss: 56.2481\n",
      "0\n",
      "Ep  413 | Reward:  -415.80 | Eps: 0.083 | Loss: 78.5964\n",
      "0\n",
      "Ep  414 | Reward:  -128.43 | Eps: 0.082 | Loss: 161.9474\n",
      "0\n",
      "Ep  415 | Reward:  -376.11 | Eps: 0.082 | Loss: 97.1255\n",
      "0\n",
      "Ep  416 | Reward:  -370.54 | Eps: 0.081 | Loss: 157.1900\n",
      "0\n",
      "Ep  417 | Reward:  -348.45 | Eps: 0.081 | Loss: 123.7990\n",
      "0\n",
      "Ep  418 | Reward:  -313.17 | Eps: 0.080 | Loss: 103.6671\n",
      "0\n",
      "Ep  419 | Reward:  -302.10 | Eps: 0.080 | Loss: 54.2693\n",
      "0\n",
      "Ep  420 | Reward:  -359.21 | Eps: 0.079 | Loss: 166.9964\n",
      "0\n",
      "Ep  421 | Reward:  -318.54 | Eps: 0.079 | Loss: 75.9837\n",
      "0\n",
      "Ep  422 | Reward:  -408.02 | Eps: 0.078 | Loss: 92.3876\n",
      "0\n",
      "Ep  423 | Reward:  -349.49 | Eps: 0.078 | Loss: 311.9269\n",
      "0\n",
      "Ep  424 | Reward:  -406.20 | Eps: 0.077 | Loss: 53.4282\n",
      "0\n",
      "Ep  425 | Reward:  -331.22 | Eps: 0.077 | Loss: 49.7704\n",
      "0\n",
      "Ep  426 | Reward:  -197.65 | Eps: 0.077 | Loss: 80.9074\n",
      "0\n",
      "Ep  427 | Reward:  -414.69 | Eps: 0.076 | Loss: 130.7727\n",
      "0\n",
      "Ep  428 | Reward:  -418.60 | Eps: 0.076 | Loss: 834.9595\n",
      "0\n",
      "Ep  429 | Reward:  -383.80 | Eps: 0.075 | Loss: 468.4817\n",
      "0\n",
      "Ep  430 | Reward:  -369.71 | Eps: 0.075 | Loss: 43.1681\n",
      "0\n",
      "Ep  431 | Reward:  -339.36 | Eps: 0.074 | Loss: 179.2505\n",
      "0\n",
      "Ep  432 | Reward:  -354.06 | Eps: 0.074 | Loss: 63.8872\n",
      "0\n",
      "Ep  433 | Reward:  -406.48 | Eps: 0.073 | Loss: 77.1134\n",
      "0\n",
      "Ep  434 | Reward:  -418.06 | Eps: 0.073 | Loss: 56.0818\n",
      "0\n",
      "Ep  435 | Reward:  -220.86 | Eps: 0.073 | Loss: 741.6460\n",
      "0\n",
      "Ep  436 | Reward:  -328.44 | Eps: 0.072 | Loss: 56.2250\n",
      "0\n",
      "Ep  437 | Reward:  -431.34 | Eps: 0.072 | Loss: 81.9163\n",
      "0\n",
      "Ep  438 | Reward:  -346.85 | Eps: 0.071 | Loss: 82.1934\n",
      "0\n",
      "Ep  439 | Reward:  -341.00 | Eps: 0.071 | Loss: 136.0878\n",
      "0\n",
      "Ep  440 | Reward:  -354.67 | Eps: 0.070 | Loss: 83.8011\n",
      "0\n",
      "Ep  441 | Reward:  -331.51 | Eps: 0.070 | Loss: 57.7364\n",
      "0\n",
      "Ep  442 | Reward:  -374.07 | Eps: 0.070 | Loss: 54.2076\n",
      "0\n",
      "Ep  443 | Reward:  -440.27 | Eps: 0.069 | Loss: 45.5499\n",
      "0\n",
      "Ep  444 | Reward:  -227.05 | Eps: 0.069 | Loss: 69.2412\n",
      "0\n",
      "Ep  445 | Reward:  -398.44 | Eps: 0.068 | Loss: 88.1649\n",
      "0\n",
      "Ep  446 | Reward:  -331.63 | Eps: 0.068 | Loss: 59.2112\n",
      "0\n",
      "Ep  447 | Reward:  -370.71 | Eps: 0.067 | Loss: 56.5279\n",
      "0\n",
      "Ep  448 | Reward:  -422.74 | Eps: 0.067 | Loss: 49.8740\n",
      "0\n",
      "Ep  449 | Reward:  -419.59 | Eps: 0.067 | Loss: 64.9221\n",
      "0\n",
      "Ep  450 | Reward:  -335.99 | Eps: 0.066 | Loss: 54.0058\n",
      "0\n",
      "Ep  451 | Reward:  -260.94 | Eps: 0.066 | Loss: 55.3024\n",
      "0\n",
      "Ep  452 | Reward:  -376.81 | Eps: 0.065 | Loss: 62.2670\n",
      "0\n",
      "Ep  453 | Reward:  -314.85 | Eps: 0.065 | Loss: 154.3341\n",
      "0\n",
      "Ep  454 | Reward:  -388.21 | Eps: 0.065 | Loss: 38.0751\n",
      "0\n",
      "Ep  455 | Reward:  -306.03 | Eps: 0.064 | Loss: 71.0393\n",
      "0\n",
      "Ep  456 | Reward:  -379.92 | Eps: 0.064 | Loss: 62.3084\n",
      "0\n",
      "Ep  457 | Reward:  -375.96 | Eps: 0.064 | Loss: 48.1390\n",
      "0\n",
      "Ep  458 | Reward:  -302.96 | Eps: 0.063 | Loss: 52.7055\n",
      "0\n",
      "Ep  459 | Reward:  -390.86 | Eps: 0.063 | Loss: 99.0337\n",
      "0\n",
      "Ep  460 | Reward:  -372.95 | Eps: 0.062 | Loss: 75.7218\n",
      "0\n",
      "Ep  461 | Reward:  -354.63 | Eps: 0.062 | Loss: 75.6325\n",
      "0\n",
      "Ep  462 | Reward:  -362.58 | Eps: 0.062 | Loss: 87.0998\n",
      "0\n",
      "Ep  463 | Reward:  -354.85 | Eps: 0.061 | Loss: 82.6451\n",
      "0\n",
      "Ep  464 | Reward:  -349.41 | Eps: 0.061 | Loss: 51.5705\n",
      "0\n",
      "Ep  465 | Reward:  -360.65 | Eps: 0.061 | Loss: 55.9831\n",
      "0\n",
      "Ep  466 | Reward:  -364.27 | Eps: 0.060 | Loss: 115.2835\n",
      "0\n",
      "Ep  467 | Reward:  -388.53 | Eps: 0.060 | Loss: 145.8553\n",
      "0\n",
      "Ep  468 | Reward:  -362.06 | Eps: 0.059 | Loss: 34.9782\n",
      "0\n",
      "Ep  469 | Reward:  -362.76 | Eps: 0.059 | Loss: 40.5331\n",
      "0\n",
      "Ep  470 | Reward:  -355.91 | Eps: 0.059 | Loss: 59.5727\n",
      "0\n",
      "Ep  471 | Reward:  -331.92 | Eps: 0.058 | Loss: 67.0645\n",
      "0\n",
      "Ep  472 | Reward:  -358.60 | Eps: 0.058 | Loss: 56.4155\n",
      "0\n",
      "Ep  473 | Reward:  -332.68 | Eps: 0.058 | Loss: 78.5741\n",
      "0\n",
      "Ep  474 | Reward:  -346.88 | Eps: 0.057 | Loss: 82.9334\n",
      "0\n",
      "Ep  475 | Reward:  -355.06 | Eps: 0.057 | Loss: 36.3169\n",
      "0\n",
      "Ep  476 | Reward:  -345.54 | Eps: 0.057 | Loss: 57.3039\n",
      "0\n",
      "Ep  477 | Reward:  -299.73 | Eps: 0.056 | Loss: 180.8470\n",
      "0\n",
      "Ep  478 | Reward:  -332.08 | Eps: 0.056 | Loss: 37.2440\n",
      "0\n",
      "Ep  479 | Reward:  -327.29 | Eps: 0.056 | Loss: 58.6896\n",
      "0\n",
      "Ep  480 | Reward:  -212.18 | Eps: 0.055 | Loss: 37.7507\n",
      "0\n",
      "Ep  481 | Reward:  -317.58 | Eps: 0.055 | Loss: 45.6594\n",
      "0\n",
      "Ep  482 | Reward:  -318.54 | Eps: 0.055 | Loss: 54.7327\n",
      "0\n",
      "Ep  483 | Reward:  -303.75 | Eps: 0.054 | Loss: 42.6072\n",
      "0\n",
      "Ep  484 | Reward:  -231.80 | Eps: 0.054 | Loss: 69.0912\n",
      "0\n",
      "Ep  485 | Reward:  -324.07 | Eps: 0.054 | Loss: 43.3285\n",
      "0\n",
      "Ep  486 | Reward:  -333.48 | Eps: 0.053 | Loss: 50.1502\n",
      "0\n",
      "Ep  487 | Reward:  -301.97 | Eps: 0.053 | Loss: 64.6540\n",
      "0\n",
      "Ep  488 | Reward:  -289.83 | Eps: 0.053 | Loss: 50.5297\n",
      "0\n",
      "Ep  489 | Reward:  -223.16 | Eps: 0.052 | Loss: 53.8229\n",
      "0\n",
      "Ep  490 | Reward:  -287.83 | Eps: 0.052 | Loss: 62.2625\n",
      "0\n",
      "Ep  491 | Reward:  -294.14 | Eps: 0.052 | Loss: 65.5514\n",
      "0\n",
      "Ep  492 | Reward:  -239.87 | Eps: 0.051 | Loss: 37.6092\n",
      "0\n",
      "Ep  493 | Reward:  -278.98 | Eps: 0.051 | Loss: 48.7426\n",
      "0\n",
      "Ep  494 | Reward:  -292.77 | Eps: 0.051 | Loss: 47.4408\n",
      "0\n",
      "Ep  495 | Reward:  -327.03 | Eps: 0.051 | Loss: 69.2694\n",
      "0\n",
      "Ep  496 | Reward:  -294.41 | Eps: 0.050 | Loss: 31.5122\n",
      "0\n",
      "Ep  497 | Reward:  -295.85 | Eps: 0.050 | Loss: 43.5188\n",
      "0\n",
      "Ep  498 | Reward:  -275.28 | Eps: 0.050 | Loss: 45.6502\n",
      "0\n",
      "Ep  499 | Reward:  -234.60 | Eps: 0.049 | Loss: 56.7284\n",
      "0\n",
      "Ep  500 | Reward:  -364.23 | Eps: 0.049 | Loss: 67.0299\n",
      "0\n",
      "Ep  501 | Reward:  -304.19 | Eps: 0.049 | Loss: 2442.0518\n",
      "0\n",
      "Ep  502 | Reward:  -292.25 | Eps: 0.048 | Loss: 38.7944\n",
      "0\n",
      "Ep  503 | Reward:  -298.20 | Eps: 0.048 | Loss: 65.4631\n",
      "0\n",
      "Ep  504 | Reward:  -250.97 | Eps: 0.048 | Loss: 46.9135\n",
      "0\n",
      "Ep  505 | Reward:  -304.83 | Eps: 0.048 | Loss: 42.1135\n",
      "0\n",
      "Ep  506 | Reward:  -321.04 | Eps: 0.047 | Loss: 1936.0341\n",
      "0\n",
      "Ep  507 | Reward:  -282.39 | Eps: 0.047 | Loss: 44.0456\n",
      "0\n",
      "Ep  508 | Reward:  -215.68 | Eps: 0.047 | Loss: 261.6350\n",
      "0\n",
      "Ep  509 | Reward:  -250.57 | Eps: 0.046 | Loss: 61.1670\n",
      "0\n",
      "Ep  510 | Reward:  -300.81 | Eps: 0.046 | Loss: 48.5757\n",
      "0\n",
      "Ep  511 | Reward:  -228.74 | Eps: 0.046 | Loss: 49.8405\n",
      "0\n",
      "Ep  512 | Reward:  -280.47 | Eps: 0.046 | Loss: 34.9609\n",
      "0\n",
      "Ep  513 | Reward:  -289.81 | Eps: 0.045 | Loss: 84.8275\n",
      "0\n",
      "Ep  514 | Reward:  -287.04 | Eps: 0.045 | Loss: 56.4080\n",
      "0\n",
      "Ep  515 | Reward:  -265.83 | Eps: 0.045 | Loss: 49.0200\n",
      "0\n",
      "Ep  516 | Reward:  -321.01 | Eps: 0.045 | Loss: 264.9389\n",
      "0\n",
      "Ep  517 | Reward:  -315.65 | Eps: 0.044 | Loss: 36.7247\n",
      "0\n",
      "Ep  518 | Reward:  -313.33 | Eps: 0.044 | Loss: 114.2464\n",
      "0\n",
      "Ep  519 | Reward:  -386.72 | Eps: 0.044 | Loss: 39.1354\n",
      "0\n",
      "Ep  520 | Reward:  -239.33 | Eps: 0.043 | Loss: 32.2338\n",
      "0\n",
      "Ep  521 | Reward:  -225.38 | Eps: 0.043 | Loss: 37.1218\n",
      "0\n",
      "Ep  522 | Reward:  -329.43 | Eps: 0.043 | Loss: 42.7786\n",
      "0\n",
      "Ep  523 | Reward:  -245.43 | Eps: 0.043 | Loss: 49.4410\n",
      "0\n",
      "Ep  524 | Reward:  -258.97 | Eps: 0.042 | Loss: 57.6116\n",
      "0\n",
      "Ep  525 | Reward:  -261.75 | Eps: 0.042 | Loss: 120.6280\n",
      "0\n",
      "Ep  526 | Reward:  -290.35 | Eps: 0.042 | Loss: 41.0142\n",
      "0\n",
      "Ep  527 | Reward:  -244.82 | Eps: 0.042 | Loss: 954.9746\n",
      "0\n",
      "Ep  528 | Reward:  -285.93 | Eps: 0.041 | Loss: 57.7338\n",
      "0\n",
      "Ep  529 | Reward:  -321.25 | Eps: 0.041 | Loss: 47.6288\n",
      "0\n",
      "Ep  530 | Reward:  -224.04 | Eps: 0.041 | Loss: 36.7410\n",
      "0\n",
      "Ep  531 | Reward:  -336.62 | Eps: 0.041 | Loss: 42.2842\n",
      "0\n",
      "Ep  532 | Reward:  -294.18 | Eps: 0.040 | Loss: 53.2862\n",
      "0\n",
      "Ep  533 | Reward:  -217.49 | Eps: 0.040 | Loss: 34.1295\n",
      "0\n",
      "Ep  534 | Reward:  -395.66 | Eps: 0.040 | Loss: 133.8854\n",
      "0\n",
      "Ep  535 | Reward:  -242.11 | Eps: 0.040 | Loss: 34.9204\n",
      "0\n",
      "Ep  536 | Reward:  -288.82 | Eps: 0.039 | Loss: 40.6544\n",
      "0\n",
      "Ep  537 | Reward:  -217.44 | Eps: 0.039 | Loss: 43.7034\n",
      "0\n",
      "Ep  538 | Reward:  -255.14 | Eps: 0.039 | Loss: 28.6080\n",
      "0\n",
      "Ep  539 | Reward:  -274.15 | Eps: 0.039 | Loss: 45.2173\n",
      "0\n",
      "Ep  540 | Reward:  -309.08 | Eps: 0.039 | Loss: 36.6888\n",
      "0\n",
      "Ep  541 | Reward:  -228.97 | Eps: 0.038 | Loss: 38.4965\n",
      "0\n",
      "Ep  542 | Reward:  -330.81 | Eps: 0.038 | Loss: 48.1939\n",
      "0\n",
      "Ep  543 | Reward:  -254.50 | Eps: 0.038 | Loss: 39.2502\n",
      "0\n",
      "Ep  544 | Reward:  -247.88 | Eps: 0.038 | Loss: 37.8452\n",
      "0\n",
      "Ep  545 | Reward:  -201.75 | Eps: 0.037 | Loss: 43.8640\n",
      "0\n",
      "Ep  546 | Reward:  -279.24 | Eps: 0.037 | Loss: 69.1265\n",
      "0\n",
      "Ep  547 | Reward:  -307.10 | Eps: 0.037 | Loss: 442.1526\n",
      "0\n",
      "Ep  548 | Reward:  -229.48 | Eps: 0.037 | Loss: 37.7358\n",
      "0\n",
      "Ep  549 | Reward:  -247.55 | Eps: 0.037 | Loss: 42.9156\n",
      "0\n",
      "Ep  550 | Reward:  -258.62 | Eps: 0.036 | Loss: 36.8351\n",
      "0\n",
      "Ep  551 | Reward:  -272.44 | Eps: 0.036 | Loss: 23.9994\n",
      "0\n",
      "Ep  552 | Reward:  -233.11 | Eps: 0.036 | Loss: 49.2244\n",
      "0\n",
      "Ep  553 | Reward:  -270.28 | Eps: 0.036 | Loss: 309.6701\n",
      "0\n",
      "Ep  554 | Reward:  -309.94 | Eps: 0.035 | Loss: 53.1591\n",
      "0\n",
      "Ep  555 | Reward:  -224.47 | Eps: 0.035 | Loss: 39.3225\n",
      "0\n",
      "Ep  556 | Reward:  -185.71 | Eps: 0.035 | Loss: 24.3839\n",
      "0\n",
      "Ep  557 | Reward:  -203.74 | Eps: 0.035 | Loss: 25.4646\n",
      "0\n",
      "Ep  558 | Reward:  -294.49 | Eps: 0.035 | Loss: 43.4310\n",
      "0\n",
      "Ep  559 | Reward:  -392.51 | Eps: 0.034 | Loss: 55.9826\n",
      "0\n",
      "Ep  560 | Reward:  -253.51 | Eps: 0.034 | Loss: 47.1287\n",
      "0\n",
      "Ep  561 | Reward:  -178.88 | Eps: 0.034 | Loss: 179.9451\n",
      "0\n",
      "Ep  562 | Reward:  -232.14 | Eps: 0.034 | Loss: 31.0357\n",
      "0\n",
      "Ep  563 | Reward:  -302.07 | Eps: 0.034 | Loss: 28.4920\n",
      "0\n",
      "Ep  564 | Reward:  -290.02 | Eps: 0.033 | Loss: 63.5368\n",
      "0\n",
      "Ep  565 | Reward:  -171.38 | Eps: 0.033 | Loss: 143.8534\n",
      "0\n",
      "Ep  566 | Reward:  -254.92 | Eps: 0.033 | Loss: 176.3387\n",
      "0\n",
      "Ep  567 | Reward:  -322.10 | Eps: 0.033 | Loss: 177.9489\n",
      "0\n",
      "Ep  568 | Reward:  -307.80 | Eps: 0.033 | Loss: 47.7265\n",
      "0\n",
      "Ep  569 | Reward:  -255.49 | Eps: 0.032 | Loss: 101.2044\n",
      "0\n",
      "Ep  570 | Reward:  -288.28 | Eps: 0.032 | Loss: 87.6142\n",
      "0\n",
      "Ep  571 | Reward:  -252.03 | Eps: 0.032 | Loss: 51.5445\n",
      "0\n",
      "Ep  572 | Reward:  -284.64 | Eps: 0.032 | Loss: 81.1539\n",
      "0\n",
      "Ep  573 | Reward:  -212.37 | Eps: 0.032 | Loss: 121.4636\n",
      "0\n",
      "Ep  574 | Reward:  -202.58 | Eps: 0.031 | Loss: 51.3719\n",
      "0\n",
      "Ep  575 | Reward:  -289.03 | Eps: 0.031 | Loss: 44.8179\n",
      "0\n",
      "Ep  576 | Reward:  -222.11 | Eps: 0.031 | Loss: 50.9125\n",
      "0\n",
      "Ep  577 | Reward:  -215.12 | Eps: 0.031 | Loss: 106.4310\n",
      "0\n",
      "Ep  578 | Reward:  -298.39 | Eps: 0.031 | Loss: 285.7853\n",
      "0\n",
      "Ep  579 | Reward:  -213.79 | Eps: 0.030 | Loss: 79.2567\n",
      "0\n",
      "Ep  580 | Reward:  -237.48 | Eps: 0.030 | Loss: 103.6293\n",
      "0\n",
      "Ep  581 | Reward:  -302.66 | Eps: 0.030 | Loss: 53.6937\n",
      "0\n",
      "Ep  582 | Reward:  -268.09 | Eps: 0.030 | Loss: 6042.8350\n",
      "0\n",
      "Ep  583 | Reward:  -285.59 | Eps: 0.030 | Loss: 264.4471\n",
      "0\n",
      "Ep  584 | Reward:  -250.86 | Eps: 0.030 | Loss: 5056.1387\n",
      "0\n",
      "Ep  585 | Reward:  -186.77 | Eps: 0.029 | Loss: 256.3089\n",
      "0\n",
      "Ep  586 | Reward:  -244.62 | Eps: 0.029 | Loss: 189.6053\n",
      "0\n",
      "Ep  587 | Reward:  -331.13 | Eps: 0.029 | Loss: 273.6256\n",
      "0\n",
      "Ep  588 | Reward:  -221.95 | Eps: 0.029 | Loss: 57.3409\n",
      "0\n",
      "Ep  589 | Reward:  -270.90 | Eps: 0.029 | Loss: 108.1623\n",
      "0\n",
      "Ep  590 | Reward:  -274.03 | Eps: 0.029 | Loss: 4681.1338\n",
      "0\n",
      "Ep  591 | Reward:  -245.01 | Eps: 0.028 | Loss: 83.3573\n",
      "0\n",
      "Ep  592 | Reward:  -269.23 | Eps: 0.028 | Loss: 54.4226\n",
      "0\n",
      "Ep  593 | Reward:  -300.92 | Eps: 0.028 | Loss: 2096.8977\n",
      "0\n",
      "Ep  594 | Reward:  -111.07 | Eps: 0.028 | Loss: 394.5726\n",
      "0\n",
      "Ep  595 | Reward:  -310.61 | Eps: 0.028 | Loss: 204.1484\n",
      "0\n",
      "Ep  596 | Reward:  -309.06 | Eps: 0.028 | Loss: 65.5946\n",
      "0\n",
      "Ep  597 | Reward:  -300.80 | Eps: 0.027 | Loss: 1092.1510\n",
      "0\n",
      "Ep  598 | Reward:  -255.60 | Eps: 0.027 | Loss: 181.1086\n",
      "0\n",
      "Ep  599 | Reward:  -327.96 | Eps: 0.027 | Loss: 110.2159\n",
      "0\n",
      "Ep  600 | Reward:  -293.94 | Eps: 0.027 | Loss: 212.2630\n",
      "0\n",
      "Ep  601 | Reward:  -217.71 | Eps: 0.027 | Loss: 122.9556\n",
      "0\n",
      "Ep  602 | Reward:  -333.61 | Eps: 0.027 | Loss: 59.5102\n",
      "0\n",
      "Ep  603 | Reward:  -287.22 | Eps: 0.026 | Loss: 48.8298\n",
      "0\n",
      "Ep  604 | Reward:  -316.01 | Eps: 0.026 | Loss: 193.1092\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(lunar,target_network_update_freq=5,replays_per_episode=50, episodes=2000)\n",
    "agent.train()\n",
    "#añado yo\n",
    "agent.save_model(\"modelo_DQN.h4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNetwork:\n",
      " DQN(\n",
      "  (fc1): Linear(in_features=8, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# agent with epsilon = 0.0 (no exploration)\n",
    "agent = DQNAgent(lunar, epsilon=0.0)\n",
    "agent.load_model(\"modelo_DQN.h2\")\n",
    "#h6 funciona bien el test y h1 tmb h2 (no va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished, score: 137.16810971967703\n",
      "Environment closed.\n"
     ]
    }
   ],
   "source": [
    "test_lunar_lander(steps_to_run_before_pause=25, agent=agent, episodes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'REINFORCE'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mREINFORCE\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m REINFORCEAgent\n\u001b[32m      2\u001b[39m lunar = LunarLanderEnv(render_mode=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'REINFORCE'"
     ]
    }
   ],
   "source": [
    "from REINFORCE import REINFORCEAgent\n",
    "lunar = LunarLanderEnv(render_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = REINFORCEAgent(lunar, episodes=5000)\n",
    "# agent.load_model(\"modelo_REINFORCE.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = REINFORCEAgent(lunar)\n",
    "agent.load_model(\"modelo_REINFORCE.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lunar_lander(steps_to_run_before_pause=75, agent=agent, episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
